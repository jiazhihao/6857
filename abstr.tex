\begin{abstract}

Vandalism has emerged as a threat to Wikipedia, because it allows exploits such as conveying
misinformation to viewers. We first present statistics on vandalism and vandals, and define a framework in which we can evaluate the success of a vandalism prevention system. We then analyze the deficiencies in Wikipedia's protection systems against vandalism. Our contributions are a user level security policy and improvements to a machine-learning based detection approach. Firstly, we propose Voting-Delayed Revisions, which allows users to downvote bad revisions to delay them from being shown to viewers. This way, editors have time to revert the vandalism before it is shown to viewers. Secondly, we add features to improve an existing vandalism detection algorithm, ClueBot NG, so that it is better able to identify vandalism. Finally, we present new usages for ClueBot NG within our Voting-Delayed Revisions framework, as well as ways adversaries could attack the two systems.

%
\end{abstract}
