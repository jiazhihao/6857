\section{Evaluation}
\label{s:eval}

The evaluation tries to answer the following questions.
\begin{itemize}
\item
Is \sys effective in discovering new integer errors in practice?
\item
How complete are \sys's reports?
\item
How many false errors are in \sys's reports?
\item
How long does it take \sys to analyze a large system such
as the Linux kernel?
\end{itemize}

All the experiments were conducted on a 64-bit Ubuntu Linux machine
equipped with Intel 3.2~G HZ CPU and 24~GB memory.

\subsection{New Bugs}
\label{s:eval:linux}

We applied \sys to the source code of the latest Linux kernel,
as well as two popular user-space applications, lighttpd and OpenSSH,
and submitted patches to the developers according to \sys's reports.
The developers confirmed and fixed more than 50 integer errors in
the Linux kernel, 1 in lighttpd, and 4 in OpenSSH.
%
The results show that \sys is effective in finding new integer
errors, and the developers are willing to fix them.

We use the Linux kernel for a case study.  \autoref{f:data:linux}
summarizes integer errors \sys discovered in its source code.
Each line represents a patch that fixes one or more integer errors; the
number is shown in the ``Error'' column if it is more than one.  We
organize the patches based on the source directories.  Most
columns are self-explanatory.  ``Description'' shows the attack
vector and what values are infected.  ``\# of prev. fixes'' shows
the number of previous commits that tried to fix the same error but
did it incorrectly.  ``Patch accepted?'' shows how the kernel
developers respond to our patches:
\begin{itemize}
\item
\ok: the kernel developers accepted the patch.
The optional ``modified'' means that they modified our patch for inclusion;
otherwise they applied our patch without modifications.
\item
fixed: the bug was already fixed in some repository other than the
mainline when \sys discovered it, so we withdrew our patch.
\end{itemize}
We omit patches that did not receive any further response.
The kernel developers also incorrectly modified three of the patches
we proposed; they withdrew these modifications after discussion on the
mailing list.

\begin{figure*}
\centering
\footnotesize
\input{data/linux}
\caption{Integer errors discovered by \sys in the latest Linux
kernel source trees.  Each line is a patchset that tries to fix one
or more bugs (the number is in the ``Error'' column if more than
one).  For each patch, we list the corresponding subsystem, the
error operation with the number of bugs, the security impact, a
description of the attack vector and affected values, the number
of previous commits that did not to fix the same problem correctly,
and how the kernel developers respond to the patchset.}
\label{f:data:linux}
\end{figure*}

\subsubsection{Distribution}

The integer errors \sys found span a wide range of kernel subsystems,
including the core kernel, drivers, file systems, and network protocols.
The core kernel has fewer integer errors, since it does not
interact with the outside as frequently as the rest of the kernel.

Multiplication appears to be the most error-prone operation, which
is often used for calculating allocation size such as $\cc{count}
\times \cc{sizeof}(...)$, especially if \cc{count} can be controlled
by an adversary.

Surprisingly,  a simple tautological comparison $<_u 0$,
comparing an unsigned integer with 0 (usually for error handling),
affected several subsystems.
One driver (wl128x) contains 36 such bugs alone, effectively
disabling almost its entire error handling paths.

\subsubsection{Impact}

The integer errors that allow out-of-bounds writes (i.e., buffer
overflow) would break the integrity of the kernel and potentially
allow privilege escalation.  They can be exploited via local access,
disk (malformed filesystem), and network.  We see a large portion
of \cc{ioctl} since it is error-prone and biased by \sys's ranking
heuristics.
%
There is also an interesting vulnerability in the sound subsystem;
an adversary can exploit it by plugging in a malicious USB audio
device that responds with bogus sampling rates, leading to kernel
hang, DoS, and buffer overflow.

Integer errors cause timing bugs in several network protocol
implementations.  For example, a user-space application tries to
set a large timeout value, but the value could overflow and end up
with a small timeout.

Error-handling related integer errors would make the kernel behave in
unanticipated ways, though they are hard to exploit by an adversary.
Most of these bugs are simple tautological comparisons.
%
Below is an interesting non-trivial case found in CAN.
\begin{align*}
((\cc{errc}\ \&\ \cc{0x7f}) \shr 8) > 127.
\end{align*}
The intent of the code is to test whether the error counter \cc{errc}
has reached certain level.  However, this
comparison will never be true because the left-hand side of the test,
which extracts 7 bits, is at most
$2^7 - 1 = 127$.  The fix is to read the right bit according to the specification,
via $\cc{errc}\ \&\ \cc{0x80}$.

Two cases (in xenbus and sctp) turned out to be not exploitable.
The kernel developers still applied our patches for clarification and
reliability improvement.

\subsubsection{Bad Fixes}
\label{s:eval:bad}

\sys discovered 7 integer errors that were previously known but
fixed incorrectly.
The ``\# of prev. fixes'' column in \autoref{f:data:linux} counts
the incorrect patches that were committed into the mainline repository;
those only proposed on the mailing list are not included.


\xw{show one case. drm?}

%
It is interesting that two bad patches were committed to fix
vulnerabilities reported on the CVE list, which received extensive
review.  We describe them below.

\paragraph{CVE-2008-3526 (sctp).}
Below is the fix that performs a sanity check on \cc{key_len} to
avoid an integer overflow and possible heap overflow if
\cc{key_len} is large.
\input{code/sctp-bad}
This sanity check in fact does not work.  Consider $\cc{key_len} =
\cc{0xffffffff}$ (i.e., \cc{UINT_MAX}).
The result of the left-hand side of the check is then \cc{0x80000000}.
Since \cc{key_len} is unsigned,  the left-hand side result
is also treated as unsigned, $2^{31}$, which bypasses the check.

After discussion with the kernel developers, we came to the conclusion
that \cc{key_len} could not become that large with input from either
user space or network by an adversary.  CVE-2008-3526 is not
exploitable, and the previous commit is unnecessary.  Our patch was
applied to clarify the case.

\paragraph{CVE-2009-4307 (ext4).}
Below is the fix that performs a sanity check
on the \cc{s_log_groups_per_flex} value, which is read from disk,
to prevent a division-by-zero DoS attack when the value is large
and the result of the shift becomes zero.
\input{code/ext4-bad}
The sanity check $(\cc{groups_per_flex} < 2)$ relies on undefined
behavior, an oversized shift.  This would lead to two potential
issues.

First, when \cc{s_log_groups_per_flex} is set to a corrupted value
like 36, $\cc{groups_per_flex} = 1 \shl 36$ is essentially $1 \shl
4 = 16$ on x86.  This will bypass the check, leaving
the two values \cc{s_log_groups_per_flex}~(36) and
\cc{groups_per_flex}~(16) inconsistent.

Second, the C compiler may rewrite undefined code in unexpected
ways.  Consider the following equivalent sanity check (which was
in the originally proposed patch), assuming \cc{groups_per_flex}
is an unsigned integer.
\input{code/ext4-badeqv}
We compiled the code using both Clang~3.0 and GCC~4.6, with optimization
option \cc{-O2}.  Clang optimizes away the check
$\cc{groups_per_flex} == 0$, since it considers the case impossible,
following the C standard.  This would make the patched code as
vulnerable as the original.  GCC~4.6 keeps the check, but
there is no guarantee that future versions will do the same.

\subsection{Completeness Validation}
\label{s:eval:complete}

We collected 36 known integer errors in the Linux kernel from the
CVE list~\cite{cve} in recent three years (excluding those found
by \sys for fairness) as a benchmark to evaluate
\sys's completeness, as shown in \autoref{f:data:cve}.  They provide
a comprehensive coverage of the whole source tree.
%For each
%case, we run \sys against both the original and the patched code
%snippets.
%Ideally \sys should catch the bugs in the original code,
%and declare that the bug is fixed in the patched code.
%
\sys is able to find 34 (94\%) of the 36 integer errors.
This shows that \sys's report is fairly complete.

\begin{figure*}
\centering
\footnotesize
\input{data/cve}
\caption{The result of applying \sys to integer errors in Linux
kernel from the CVE list.  We list the corresponding
subsystem, the error operations, whether \sys catches the expected
bugs in the original code, and whether \sys determines that the bug
is fixed in the patched code.}
\label{f:data:cve}
\end{figure*}

\sys misses the following two cases.

\paragraph{CVE-2009-4307 (ext4).}
This bug is due to a possible division by zero that is caused by
an oversized left shift on PowerPC.  \sys is able to catch the
oversized shift, but not the division by zero, because in \sys's
semantics a left shift never produces zero, as discussed in
\autoref{s:sema:def}.

\paragraph{CVE-2010-3865 (rds).}
This bug is due to an addition overflow that happens in an accumulation
loop.  \sys cannot catch the bug since it unrolls the loop only
once.

\subsection{False Errors}

To evaluate how many false errors are in \sys's reports,
We first tested \sys on the patched code of these CVE cases
in \autoref{s:eval:complete},
and expected that ideally \sys would not report any errors.
The result is also shown in \autoref{f:data:cve}.
\sys declares no bug in 29 of the 36 cases, timeouts in 1 case, and
reports errors in 6 cases.
%
In these 6 cases,
the patched code of CVE-2010-3873 (x25)
contains additional integer errors that are covered by CVE-2010-4164,
which \sys correctly identified;
four cases contain either new errors or bad fixes,
as we have shown in \autoref{s:eval:linux}.
There is one false error in CVE-2011-4097 (oom), as detailed below.

\input{code/oom}
The code snippet
computes a score proportional to process $p$'s memory consumption.
It sums up different numbers of
memory pages $p$ takes, divide the result by the total number
of pages to get a ratio, and scale it by 1000.
When the whole system is running out of memory,
the kernel kills the process with the highest score
to free more memory.

The patch changes the type of \cc{points} from \cc{int} to \cc{long} because
\cc{points} could be large on 64-bit systems; multiplying it by
1000 could overflow and produce an incorrect score,
causing an innocent process being killed.

There is an implicit rule that the sum of these numbers of pages
(e.g., from \cc{get_mm_rss}) is at most \cc{totalpages}, so the
additions never overflow.  \sys does not understand the rule and
reports false errors on these additions.

The false error rate, recompensed by the raking heuristic described in Section
\ref{s:rank}, is practical in analyzing large scale systems. In our experience
with the Linux kernel, \sys reports 3350 warnings in which the overflowed
results are used for memory allocation. We inspected 97 of them in detail,
focusing on operands that come from untrusted sources. It took us roughly 12
hours to discover the first batch of 6 exploitable bugs in the latest kernel.
The other 91 warnings are either harmless overflows or false warnings.
Most of the false warnings are due to imprecise inter-procedure range analysis
or lack of domain-specific knowledge.

% first batch: ?, (aacraid), uvc, drm, vmwgfx, vt6656, comedi

\subsection{Performance}
\label{s:eval:perf}

To measure the performance, we ran \sys against the Linux kernel
3.2 source code, with 12 CPU cores.  We set the timeout
to 5 seconds for each constraint solving query.   \sys analyzed
8637 files, 10 of which timed out, and made 411,851 solving queries.
The predicate generation and constraint solving (excluding compilation)
cost 22 minutes.  This shows that \sys can finish analyzing a large
system within a reasonable amount of time.

As discussed in \autoref{s:gen:opt}, \sys rewrites error checking
idioms for better performance.  We measured the solving time of three
equivalent forms: division, multiplication, and overflow detection
circuit, for both 32- and 64-integers, respectively.  The result
is shown in \autoref{f:udiv}.  Each test is repeated 1000 times.
For a single unsigned division operation this optimization can
achieve up to 2.5$\times$ speedup.

\begin{figure}
\centering
\input{data/udiv}
\caption{Solving time of three unsigned multiplication checking forms:
division, $2n$-bit multiplication, and the specialized overflow
detection predicate, measured in milliseconds, for both 32- and 64-bit
integers.}
\label{f:udiv}
\end{figure}
