\section{Integer Semantics}
\label{s:sema}

\sys assumes two's complement~\cite[4.2.1]{intel:vol1},
a de facto standard integer representation on modern architectures.
An $n$-bit signed integer is in the bounds $-2^{n-1}$ to $2^{n-1}-1$,
with the most significant bit indicating the sign,
while an $n$-bit unsigned integer is in the bounds $0$ to $2^n-1$.

\sys assumes that programmers expect the result of an $n$-bit
arithmetic operation to equal to that of the corresponding mathematical
($\infty$-bit) operation.
In other words, the result should fall in the $n$-bit integer bounds.
%
Any out-of-bounds operation violates the expectation and implies an
error, unless the operation is in the white list of code patterns
that \sys explicitly allows (see \autoref{s:sema:whitelist}).

\subsection{In-Bounds Integer Operations}
\label{s:sema:sec}

We describe the requirement of producing an in-bounds result for each
integer operation, as listed in \autoref{f:in-bounds}.
%
An operation may have a subscript $s$ or $u$ to indicate whether
it operates on signed or unsigned integers, respectively.

\begin{figure}
\small
\centering
\begin{tabular}{l@{ }l@{ }lll}\toprule
\multicolumn{3}{l}{Integer operation} & In-bounds requirement \\
\midrule
$x +_s y$, & $x -_s y$, & $x \times_s y$
& $x_{\infty}\ \textrm{op}\ y_{\infty} \in [-2^{n-1}, 2^{n-1}-1]$
\\
$x +_u y$, & $x -_u y$, & $x \times_u y$
& $x_{\infty}\ \textrm{op}\ y_{\infty} \in [0, 2^n-1]$
\\
$x /_s y$ & &
& $y \neq 0 \land (x \neq -2^{n-1} \lor y \neq -1) $
\\
$x /_u y$ & &
& $y \neq 0$
\\
$ x \shl y$, & $x \shr y$ &
& $y \in [0, n-1]$
\\
$(T)x$ & &
& see ``conversion'' in \autoref{s:sema:sec}
\\
\bottomrule
\end{tabular}
\caption{In-bounds requirements of integer operations.
Both $x$ and $y$ are $n$-bit integers; $x_{\infty}, y_{\infty}$
denote their $\infty$-bit mathematical integers.}
\label{f:in-bounds}
\end{figure}

\paragraph{Addition, subtraction, and multiplication.}
The arithmetic result of an $n$-bit signed additive or multiplicative
operation should fall in $[-2^{n-1}, 2^{n-1}-1]$,
and that of an unsigned operation should fall in
$[0, 2^{n}-1]$.
For example,
$2^{31}\times_u 16$ is not in bounds,
because the expected arithmetic product $2^{35}$ is out of the bounds
of $32$-bit unsigned integers.

\paragraph{Division.}
The divisor should be non-zero.  Particularly, the signed division
$-2^{n-1} /_s {-1}$ is not in bounds, because the expected arithmetic
quotient $2^{n-1}$ is out of the $n$-bit signed integer bounds,
which is at most $2^{n-1}-1$.

\paragraph{Shift.}
For $n$-bit integers, the shifting amount should be non-negative
and at most $n-1$, as per the C standard~\cite[6.5.7]{c11}.
%
Unlike multiplication, \sys assumes that programmers are aware of
the fact that a shift operation is lossy since it shifts some bits
out.  Therefore, \sys considers $x \shl 1$ always in bounds, while
$x \times_u 2$ is not.

\paragraph{Conversion.}
Lossy truncations and sign conversions are common practice in
C code.  Therefore,
%, and they can be found by invoking GCC with \cc{-Wconversion}.
\sys does not impose any restrictions on a conversion,
unless its result is used in one of the following cases:

\paragraph{$(1)$ Comparison.}
A comparison should not be always true or false (i.e., tautological
comparison) due to an integer conversion, which otherwise would
disable part of the control flow.

For example, in \autoref{f:olpc-sign} the intent of the comparison
$\cc{status == -1}$ was to check whether \cc{read_status} returns
${-1}$ on error.  However, since the function returns an unsigned 8-bit
integer, which is zero-extended to \cc{int} according to C's
conversion rules, \cc{status} is non-negative.  Consequently,
the comparison always evaluates to false, which disables the error
handling.

\begin{figure}
\centering
\input{code/olpc-sign}
\vspace{-1em}
\caption{An integer error in the OLPC secondary display controller
driver of the Linux kernel.  Since \cc{->read_status()} returns an
unsigned 8-bit integer, the value of \cc{status} is in the bounds
$[0, 255]$.  Comparing \cc{status} with ${-1}$ will always be false,
which breaks the error handling.}
\label{f:olpc-sign}
\end{figure}

\paragraph{$(2)$ Array index.}
An array index should be non-negative,
otherwise it would lead to out-of-bounds access.

\paragraph{$(3)$ Data size.}
A data size should be non-negative, otherwise it would be misinterpreted
as a large positive value and lead to out-of-bounds access.

\autoref{f:ax25-sign} shows an example of a negative size in the
Linux kernel.  The third parameter of $\cc{copy_from_user}$ should
be non-negative since it indicates the number of bytes to be copied
from user space to kernel.  However, an adversary could supply
${-1}$ for \cc{optlen} from user space, which will bypass both
sanity checks:
according C's conversion rules, \cc{optlen} is interpreted as positive
in the first comparison because the type of the right-hand side
\cc{sizeof(int)} is unsigned, while it is still considered as
negative in the second comparison because the type of the right-hand
side \cc{IFRAMESIZ} is signed.
The negative \cc{optlen} is later used in the call to \cc{copy_from_user}
as the size parameter, which flags an integer error.

\begin{figure}
\centering
\input{code/ax25-sign}
\vspace{-1em}
\caption{An integer error in the AX.25 network protocol implementation
of the Linux kernel (CVE-2009-2909).  A negative \cc{optlen} will
bypass both sanity checks due to sign misinterpretation and reach
the \cc{copy_from_user} call, which interprets \cc{optlen}
as a large positive integer.  Depending on the architecture-specific
implementation, the consequences range from a silent failure, a
kernel crash, to a stack overflow.
}
\label{f:ax25-sign}
\end{figure}

\subsection{Equivalence}
\label{s:sema:eqv}

\if 0
Let $\uintmax(n)$ denote the largest $n$-bit unsigned integer ~(i.e.,
$2^n-1$).  Consider two functionally equivalent expressions $x -_u
1$ and $x +_u \uintmax(n)$, where $x$ is an $n$-bit unsigned integer.
According to \autoref{f:in-bounds}, the in-bounds requirement of
$x -_u 1$ is $x \geq_u 1$, while that of $x +_u \uintmax(n)$ is $x
= 0$.
\fi
As explained in \autoref{s:sema:sec}, \sys imposes different in-bounds
requirements for $x \shl 1$ and $x \times_u 2$, despite the fact
that they are functionally equivalent.
Any compiler optimization that rewrites $x \times_u 2$ to $x \shl
1$ will destroy the integer semantics.
%
%
Even worse, C compilers like GCC may completely
optimize away checks like $a + 1 < a$ if $a$ is a signed integer
or a pointer~\cite{gcc:signed-overflow,us-cert:gcc}, unless a special
option \cc{-fwrapv} or \cc{-fno-strict-overflow} is
given.  To avoid the interference, \sys is designed to run with
these optimizations disabled.

\subsection{Overflow Semantics}
\label{s:sema:def}

Consider the following code snippet.
\input{code/array-neg-index}
\sys would catch $x +_s y$ if it overflows.  On many architectures
the overflowed index becomes a negative value~(e.g., on x86).  To
further catch the negative array index, \sys
needs to continue evaluating $x +_s y$, even if it overflows.
Signed overflow, however, is undefined behavior in C.  To catch
more integer errors, \sys thus defines the semantics for integer
operations that the C standard specifies as undefined behavior, as
follows:
\begin{itemize}
\item
The signed overflow wraps around using the two's complement.
\item
The shifting amount for an $n$-bit integer wraps around at $n$,
similarly to x86's shift instructions.  For example, shifting
a 32-bit integer by 32 bits is the same as by $0$ bit,
so we have $1 \shl 32 = 1$.
\end{itemize}
Division by zero remains undefined.  \sys does not consider the case
in further expressions.

\sys may miss integer errors that are not modeled by the semantics.
Consider the expression $x / (1 \shl 32)$, which will trigger a
division by zero on PowerPC.  \sys will be able to detect the
oversized shift, but not the division by zero, since \sys evaluates
the divisor to 1.

\subsection{White Listing Idioms}
\label{s:sema:whitelist}

Developers often use overflowed results to defend against integer
overflows.  \sys recognizes such idioms and avoid reporting them
as integer errors, as listed in \autoref{f:whitelist}.  For example,
given two $n$-bit unsigned integers $x$ and $y$, a popular overflow
checking idiom is as follows:
\begin{equation*}
x +_u y <_u x.
\end{equation*}
This idiom is useful when the sum is needed later in the code.
To avoid reporting the benign overflow,
\sys rewrites it to the following equivalent non-overflow form:
\begin{equation*}
\uintmax(n) -_u x >_u y.
\end{equation*}
Here $\uintmax(n)$ denotes the largest $n$-bit unsigned integer~(i.e.,
$2^n - 1$).

Note that \sys does not recognize the overflowed comparison $x
\times_u y <_u x$ as a valid integer error check.  For example,
given $x = \cc{0x1fffffff}$ and $y = 16$, their product evaluates
to a larger value $\cc{0xfffffff0}$, which both overflows and
bypasses the check.  A correct check is $(x \times_u y) /_u y \neq
x$, or an non-overflow form, $\uintmax(n) /_u x > y$.
\if 0
In addition, \sys accepts user-provided idioms tailored for the
code being analyzed.  For example, in the Linux kernel to set a
timer that expires after \cc{delay} ticks one often invokes
\cc{mod_timer(..., jiffies + delay)}, where \cc{jiffies} is the
number of ticks since the machine started.  \sys recognizes
this idiom and ignores the addition \cc{jiffies + delay} that may
theoretically overflow.
\nz{What does this spec look like?  Do you literally allow the
ASCII string ``jiffies + delay'', or do you allow a more general
pattern?  How general?  ``jiffies + *''?  Or ``jiffies + *'' in
the last argument of {\tt mod\_timer}?}
\fi

\begin{figure}
\centering
\begin{tabular}{ll}
\toprule
Overflowed check & Equivalent check \\ \midrule
$x + y <_u x$ & $x >_u \uintmax(n) - y$ \\
$x - y <_s 0$ & $x <_u y$ \\
$(x \times y) /_u y \neq x$ & $x >_u \uintmax(n) /_u y$   \\
\bottomrule
\end{tabular}
\caption{Examples of overflowed check idioms that \sys recognizes.
Here $\uintmax(n)$ denotes the largest $n$-bit unsigned integer.}
\label{f:whitelist}
\end{figure}
