\section{Common Pitfalls}
\label{s:common}

This section summarizes common integer error patterns and the way
to fix them.

A large portion of integer errors found in the Linux kernel are due
to missing or incorrect bound checks for data from untrusted sources.
The fix is to add or correct the sanity check, and return \cc{-EINVAL}
or silently limit the value to the bounds.

Multiplication for calculating allocation size seems particularly
prone to integer errors.  The Linux kernel provides the function
\cc{kcalloc(count, size)} that checks for multiplication overflow
of \cc{count} and \cc{size} and additionally zeroes the allocated
memory.  In fact, almost every call to \cc{kzalloc(count * size)},
which also zeros the memory, may be substituted with \cc{kcalloc}
for better reliability.  In less performance-critical code,
\cc{kmalloc} may also be substituted with \cc{kcalloc}.

Similarly, in user space \cc{calloc} may be used in favor of
\cc{malloc} if performance is not the highest priority,
assuming that libc's \cc{calloc} implementations is resistant
to the multiplication overflow issue~\cite{rus-cert:calloc}.  It
is worth noting that, however, allocating elements in C++ like \cc{new
int[n]} is dangerous without correctly bounding $n$.  GCC so far
does not generate any overflow checking code for the \cc{new}
operator~\cite{gcc-new}.

\xw{$x \times y < ??$}

Using an unsigned integer for return value checking is often a mistake,
since in practice negative return values are used for error status.
The obviously wrong check $(\cc{uint} < 0)$ yet has bitten several
drivers and even the core kernel.  A trickier form is $(\cc{uchar}
< 0)$, where the left-hand side is zero-extended so that it can
never be negative.  In most cases the fix is to simply use the
signed type instead.

Using a signed integer in bounds checking needs extra cautious.  As
shown in \autoref{f:ax25-sign}, limiting the upper bound of signed
$n$ with $n > 16$ will be bypassed for a negative $n$, which could
lead to an integer error if $n$ is used as an array index or ``size''
parameter.  On the other hand, limiting the lower bound of signed
$n$ with $n < \cc{sizeof}(\cc{int})$ will be bypassed, too, when
$n$ is negative, since $n$ is misinterpreted as unsigned.  The fix
is usually to compare $n$ with 0 or change its type to unsigned.

Using \cc{char} as an array index is a common mistake, since a
character can easily go negative when the value is beyond 127,
leading to an out-of-bounds access.  This bug pattern has appeared
in many applications, including bash (CA-1996-22) and recently
lighttpd (CVE-2011-4362, found by \sys).  The fix is to simply
change the type to unsigned.

A tricky variant of this bug pattern, which happened to the Apache
web server (CVE-2009-0023), is using the result of $\cc{tolower}(c)$
as the array index, without noticing that in POSIX \cc{tolower}
returns a signed \cc{int}.  The Linux kernel's \cc{tolower} returns
an unsigned \cc{char} and does not have the problem.

Oversized shifting bit the ext4 file system (CVE-2009-4307),
as we have discussed in \autoref{s:eval:linux}.
It also disabled Google Native Client sandboxing mechanism~\cite{nacl}.
The fix is to check the shifting amount before the shift.

%ABI on 64-bit S/390, PowerPC, SPARC, and MIPS
%and 32-bit system call parameters~\cite[CVE-2009-0029]{cve}
